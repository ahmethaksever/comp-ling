# -*- coding: utf-8 -*-
"""Copy of Assignment 4 - Auto Correction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eKmpVH0u1AnUVZHzFoxaaHfqUWpgWeCD

# <font color='#FFBD33'>**Assignment 4 - Auto Correction**</font> 

This is <font color='cyan'>Assignment 4</font> for the LING360 - Computational Methods in Lingustics course and it is worth a total of  <font color='cyan'>**5 points**</font>.
The assignment covers edit distance and its utilization. 

The topics include:
1. Regular Expressions
1. Edit Distance


There's a total of  <font color='cyan'>**2 main tasks**</font> and <font color='cyan'>**5 subs tasks**</font>. For each task, please write your code between the following lines:

```
## YOUR CODE STARTS



## YOUR CODE ENDS
```

Before working on the assignment, please copy this notebook to your own drive. You can use ```Save a copy in Drive``` under the ```File``` menu on top left.

Please, run every cell in your code to make sure that it works properly before submitting it. 

Once you are ready to submit, download two versions of your code:

*   Download .ipynb
*   Download .py

These are both available under the ```File``` menu on top left. 

Then, compress your files (zip, rar, or whatever) and upload the compressed file to Moodle.

If you have any questions, please contact with karahan.sahin@boun.edu.tr
"""

# FIRST, RUN THIS LINE (IMPORTING CORPUS FILE FROM THE SOURCE)
! wget https://github.com/maidis/turkish-parallel-corpora/blob/master/kde4/kde4_tr_trunk_20181124.tr

"""## <font color='#FFBD33'>**Q1:** Get and Clean Data</font> `2 points`

In computational linguistics, you might need to deal with different data sources, and most of them will be dirty and contain HTML tags, emojis, and other unnecessary content. Therefore, you need deal with them before starting to work on your data.

### <font color='#FFBD33'>**Q1.1:** Read and Clean Corpus</font> `0.5 Points`

Just read the data and clean html tags in the data. Also lower all the characters so that we don't have to deal with sentence beginning with different versions of the same words.

<font color='#FFBD33'>**Instructions:**</font>

1. Import and read file `kde4_tr_trunk_20181124.tr` using the `open()` function and assign it to a variable called `corpus`, as we have seen previously.
1. Then clean the HTML tags within the text via `re.sub()` function.
1. Lower all characters in the corpus.
"""

## YOUR CODE STARTS
import re
with open("kde4_tr_trunk_20181124.tr", "r", encoding = "utf-8") as f:
  corpus = f.readlines()
  removedLines = []
  for line in corpus:
    removedLine = re.sub('<.*?>|\n', "", line)
    removedLines.append(removedLine.lower())

print(removedLines)

## YOUR CODE ENDS

"""### <font color='#FFBD33'>**Q1.2:** Tokenize Corpus</font> `0.5 Points`

Tokenize all the words after cleaning corpus the from the html tags. While tokenizing the data, remove tokens which only consist of numbers, punctuations, or single letter characters. 

<font color='#FFBD33'>**Instructions:**</font>

1. Either tokenize via by custom function as we did in Assignment 3 or use `nltk.wordpunkt_tokenize()` function to tokenize your corpus.
1. Assign tokenized corpus into `tokens` variable
1. Define a variable named `cleaned_tokens` which is an empty list
1. Iterate over `tokens` list and only append those that are not
  1. Only consist of numbers `token.isnum() == True`
  1. Only consist of punctuations `token.isalpha() != True`
  1. Only consist of single character `len(token) =< 1`

"""

## YOUR CODE STARTS
def tokenize(sentence):
  removed_sentence = re.sub("[\.|\!|\?|\,|\:|\;\"]","",sentence)
  splitted_sentence = removed_sentence.split()
  tokens = []
  for word in splitted_sentence:
    if word.isalpha() == True:
      tokens.append(word)
  return tokens

tokens = []

for line in removedLines:
  if len(line) > 1:
    tokenizedline = tokenize(line)
    for token in tokenizedline:
      tokens.append(token)

cleaned_tokens = []

for token in tokens:
  if token.isnumeric() == False or token.isalpha() == True or len(token) > 1:
    cleaned_tokens.append(token)

print(cleaned_tokens)



## YOUR CODE ENDS

"""### <font color='#FFBD33'>**Q1.3:** Get Token Counts</font> `1 Points`

Get the token counts and sort them in a descending order (we did this in Lab 5). The token counts will be used to provide the best suggestion by identifying the most frequent words in the corpus. When making a suggestion using edit distance, we want to pick the most frequent word.

<font color='#FFBD33'>**Instructions:**</font>
1. Create a new `Counter()` object with `cleaned_tokens` as its argument and assign it to a variable named `token_count`.
2. Then sort the `token_count` by its counts in the corpus using the `sorted` function in descending order as we have seen in Lab 5.
3. Finally turn it into a list again and assign it to a variable named `sorted_keywords`.

"""

import collections
from collections import Counter

## YOUR CODE STARTS
token_count = collections.Counter(cleaned_tokens)
sorted_keywords = sorted(token_count.items(), key=lambda x: x[1], reverse=True)
print(sorted_keywords)

## YOUR CODE ENDS

"""## <font color='#FFBD33'>**Q2:** Auto Correction</font> `3 points`

Now that we have the data, you can implement an auto correction module. But you don't just recommend suggestions with minimum edit distance but you will be improving them according the statistical information in your corpus. Also you will be saving the previously selected corrections. 
You will be using pre-defined edit distance library so that you don't have to implement it from scratch. 

"""

#install the editdistance library
!pip install editdistance --quiet

## Example usage 
# You don't have to re-invent everything on your own, just find the library for it :) 
import editdistance
editdistance.distance("gelebildi", "gelemedi")

"""### <font color='#FFBD33'>**Q2.2:** Recommend with Edit Distance</font> `1.5 Points`

Write your suggestion function using the algorithm below.

<font color='#FFBD33'>**Instructions:**</font>
1. First, check whether you have the word in your corpus. If it is, return a list containing only your target `word`.
1. If it is not available in your corpus, check the edit distance between your target word and each word in the corpus using a `for` loop.
1. After saving the edit distance between each word in the corpus and your target word, find the minimum edit distance and assign it to a variable named `min_dist`.
1. Define an empty list called `suggestions`.
1. Then iterate over `sorted_keywords` and add suggested words (i.e. words with the minimum edit distance from your target word) to the `suggestions` list until the list has a length of `n_suggestions`, which is a parameter determining how many words will be suggested by your function.
1. Finally return the `suggestions` list.
"""

def getSuggestionsWithEditDistance(word, n_suggestions):
    """
    Suggest number of candidates which for a given possible incorrect word.
    """
    ## YOUR CODE STARTS
    dict_edit = dict()
    suggestions = []
    if word in cleaned_tokens:
      return word
    else:
      for i in sorted_keywords:
        dict_edit[i[0]] = editdistance.distance(word, i[0])
      suggestions = sorted(dict_edit, key=dict_edit.get, reverse = False)[:n_suggestions]
      return suggestions

    #example
getSuggestionsWithEditDistance("olöadı", 7)

    ## YOUR CODE ENDS

"""### <font color='#FFBD33'>**Q2.3:** Final Product</font> `1.5 Points`

Final product can be utilized in everyday life, so you will be writing a mini application on top of it. 

<font color='#FFBD33'>**Instructions:**</font>
1. Take input from the user via using `input()` function and assign it to a variable named `candidate`.
1. Then run the `getSuggestionsWithEditDistance()` where `n_suggestion=5` for input word, and .
1. Print each option with its correct index via using the `enumerate()` function as "`index`. `suggestion`".
1. Ask the index from the user and save the corresponding incorrect-correct match to `MEMORY` dictionary.
1. Go back to the top, first try to find the `word` in `MEMORY`, so that you don't need to calculate over and over again.
1. If it is in `MEMORY`, print "The correct word is `your_word`".

<font color='#FFBD33'>**Note:**</font>
1. `input()` function returns only strings, so if you are giving numerical input, please translate to integer via `int()`.
2. Do not print suggestions if you have an answer in the `MEMORY`.
3. Example Usage of `enumerate()`
  ```python
  my_list = ["a", "b", "c"]
  for i in enumerate(my_list):
    print(i)

  # Output:
  # (0, "a")
  # (1, "b")
  # (2, "c")
  ```

###  <font color='#FFBD33'>Example Outputs</font>
1. First Example

```bash
Your word is: gelmesm
Selected corrected version:
0. gelemedi
1. gelmedi
2. gelmesi
3. gelmezdi

Please give your response: 3
Your answer is saved as "gelmesm -> gelmezdi"
```

2. After first example

```bash
Your word is: gelmesm
The correct word is "gelmezdi"
```
"""

MEMORY = {}

def AutoCorrect(word):
    """
    AutoCorrect function translates incorrect words into correct
    -i: 
      word:string: incorrect word candidate
    :returns: None
    """
    ## YOUR CODE STARTS
    min_liste = getSuggestionsWithEditDistance(word, 5)
    if word in MEMORY.keys():
      print("Your word is:", word)
      return f"The correct word is '{min_liste[MEMORY.get(word)]}'"

    else:
      for index, suggestion in enumerate(min_liste):
        print(index, suggestion)
      user_input = input("Please give your response:")
      MEMORY[word] = int(user_input)
      return f"Your answer is saved as {word} -> {min_liste[MEMORY[word]]}"

    ## YOUR CODE ENDS
    pass
